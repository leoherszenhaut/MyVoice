{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand recognition - Dev Sliders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hand(img, Hlower=0, Slower=27, Vlower=25, Hupper=9, Supper=214, Vupper=162, dil1_iter=2, \n",
    "                     erode1_iter=1, erode2_iter=1, dil2_iter=5, dil3_iter=4, dil4_iter=2, resize = True):\n",
    "    if resize:\n",
    "        # Optional - resize the image by half\n",
    "        img = cv2.resize(img, (0,0), fx=0.5, fy=0.5) \n",
    "\n",
    "    #Convert to HSV color space\n",
    "    hsv_frame = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    #Create a binary image with where white will be skin colors and rest is black\n",
    "    mask = cv2.inRange(hsv_frame,np.array([Hlower,Slower,Vlower]),np.array([Hupper,Supper,Vupper]))\n",
    "\n",
    "    #Kernel matrices for morphological transformation    \n",
    "    kernel_square = np.ones((11,11),np.uint8)\n",
    "    kernel_ellipse= cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n",
    "\n",
    "    #Perform morphological transformations to filter out the background noise\n",
    "    f = cv2.dilate(mask,kernel_ellipse,iterations = dil1_iter)\n",
    "    f = cv2.erode(f,kernel_square,iterations = erode1_iter)    \n",
    "    f = cv2.dilate(f,kernel_ellipse,iterations = dil2_iter)  \n",
    "    f = cv2.erode(f,kernel_square,iterations = erode1_iter)    \n",
    "    f = cv2.medianBlur(f,15)\n",
    "    kernel_ellipse= cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(8,8))\n",
    "    f = cv2.dilate(f,kernel_ellipse,iterations = dil3_iter)\n",
    "    kernel_ellipse= cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n",
    "    f = cv2.erode(f,kernel_square,iterations = erode2_iter)   \n",
    "    f = cv2.dilate(f,kernel_ellipse,iterations = dil4_iter)\n",
    "    f = cv2.medianBlur(f,15)\n",
    "    threshold = cv2.threshold(f,127,255,0)[1]\n",
    "#     cv2.imshow('BGclean',ret)\n",
    "\n",
    "    #Find contours of the filtered frame\n",
    "    _, contours, hierarchy = cv2.findContours(threshold,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)   \n",
    "\n",
    "    #Find Max contour area (Assume that hand is in the frame)\n",
    "    max_area=100\n",
    "    ci=0\t\n",
    "    for i in range(len(contours)):\n",
    "        cnt=contours[i]\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if(area>max_area):\n",
    "            max_area=area\n",
    "            ci=i  \n",
    "\n",
    "    try:\n",
    "        cnts = contours[ci]\n",
    "    except IndexError:\n",
    "        print(\"No contour found\")\n",
    "        return img, img\n",
    "    #Largest area contour  \n",
    "    cnts = contours[ci]\n",
    "\n",
    "    #Print bounding rectangle\n",
    "    # x,y is top left corner\n",
    "    x,y,w,h = cv2.boundingRect(cnts)\n",
    "\n",
    "    # Green Rectangle\n",
    "#     frame = cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "    # The idea here is to see if the crop is wider or taller. based on this, try as best as possible to crop\n",
    "    # a square. This is only a problem when we are near the edge of the image.\n",
    "\n",
    "    if h > w:\n",
    "        x_center = x + w/2.0\n",
    "        x_start = int(x_center - h*0.5)\n",
    "        x_end = int(x_center + h*0.5) \n",
    "        y_start = y\n",
    "        y_end = y + h\n",
    "        # light blue rectangle\n",
    "        img = cv2.rectangle(img, (x_start, y_start), (x_end, y_end), (255, 255, 0), 2)\n",
    "    else:\n",
    "        y_center = y + h/2.0\n",
    "        x_start = x\n",
    "        x_end = x + w\n",
    "        y_start = int(y_center - w*0.5)\n",
    "        y_end = int(y_center + w*0.5)\n",
    "        # yellow rectangle\n",
    "        img = cv2.rectangle(img, (x_start, y_start), (x_end, y_end), (0, 255, 255), 2)\n",
    "\n",
    "#     print('x',x,'y',y, 'h',h,'w',w)\n",
    "\n",
    "    # Cropping notes:\n",
    "    # When cropping the image, x & y start at top left.\n",
    "    # y is from top to buttom of the image\n",
    "    # x is from lef to right\n",
    "    # These only apply if we put Y first when indexing: crop = img[ystart:ystop, xstart:xstop]\n",
    "\n",
    "    crop = img[y_start : y_end, x_start : x_end]\n",
    "                        \n",
    "#     font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "#     cv2.putText(frame,'TPF:' + str(time.time()-start_time),(10,50),font,1,(255,255,255),2)     \n",
    "\n",
    "    try:\n",
    "        crop = cv2.resize(crop, (200, 200))\n",
    "    except:\n",
    "        crop = img[0 : 10, 0 : 10]\n",
    "        crop = cv2.resize(crop, (200, 200))\n",
    "    return img, crop\n",
    "    \n",
    "def create_trackbar(name, default_value, l_limit = 0, u_limit = 255):\n",
    "    cv2.createTrackbar(name,'TrackBars',l_limit, u_limit, nothing)\n",
    "    cv2.setTrackbarPos(name, 'TrackBars', default_value)\n",
    "    \n",
    "def nothing(x):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a window for HSV track bars\n",
    "cv2.namedWindow('TrackBars', cv2.WINDOW_FREERATIO)\n",
    "\n",
    "create_trackbar('Hlower', 0)\n",
    "create_trackbar('Slower', 27)\n",
    "create_trackbar('Vlower', 25)\n",
    "create_trackbar('Hupper', 9)\n",
    "create_trackbar('Supper', 214)\n",
    "create_trackbar('Vupper', 162)\n",
    "\n",
    "create_trackbar('dilate1_iterations', 2, u_limit = 10)\n",
    "create_trackbar('dilate2_iterations', 5, u_limit = 10)\n",
    "create_trackbar('dilate3_iterations', 4, u_limit = 10)\n",
    "create_trackbar('dilate4_iterations', 2, u_limit = 10)\n",
    "create_trackbar('erode1_iterations', 1, u_limit = 10)\n",
    "create_trackbar('erode2_iterations', 1, u_limit = 10)\n",
    "\n",
    "\n",
    "while True:\n",
    "    start_time = time.time()\n",
    "\n",
    "    Hlower = cv2.getTrackbarPos('Hlower','TrackBars')\n",
    "    Slower = cv2.getTrackbarPos('Slower','TrackBars')\n",
    "    Vlower = cv2.getTrackbarPos('Vlower','TrackBars')\n",
    "    Hupper = cv2.getTrackbarPos('Hupper','TrackBars')\n",
    "    Supper = cv2.getTrackbarPos('Supper','TrackBars')\n",
    "    Vupper = cv2.getTrackbarPos('Vupper','TrackBars')\n",
    "    dil3_iter = cv2.getTrackbarPos('dilate3_iterations','TrackBars')\n",
    "    dil4_iter = cv2.getTrackbarPos('dilate4_iterations','TrackBars')\n",
    "    dil1_iter = cv2.getTrackbarPos('dilate1_iterations','TrackBars')\n",
    "    erode1_iter = cv2.getTrackbarPos('erode1_iterations','TrackBars')\n",
    "    erode2_iter = cv2.getTrackbarPos('erode2_iterations','TrackBars')\n",
    "    dil2_iter = cv2.getTrackbarPos('dilate2_iterations','TrackBars')\n",
    "\n",
    "    img1 = cv2.imread('/Users/idofarhi/Documents/ITC/Projects/ASL/crop_test_images/1.jpg')\n",
    "    frame, crop = extract_hand(img1, Hlower, Slower, Vlower, Hupper, Supper, Vupper, dil1_iter, erode1_iter, erode2_iter, dil2_iter, dil3_iter, dil4_iter)\n",
    "    cv2.imshow('original image 1', frame)\n",
    "#     cv2.imshow('crop 1',crop)\n",
    "    \n",
    "    img2 = cv2.imread('/Users/idofarhi/Documents/ITC/Projects/ASL/crop_test_images/2.jpg')\n",
    "    frame, crop = extract_hand(img2, Hlower, Slower, Vlower, Hupper, Supper, Vupper, dil1_iter, erode1_iter, erode2_iter, dil2_iter, dil3_iter, dil4_iter, False)\n",
    "    cv2.imshow('original image 2', frame)\n",
    "#     cv2.imshow('crop 2',crop)\n",
    "    \n",
    "    img3 = cv2.imread('/Users/idofarhi/Documents/ITC/Projects/ASL/crop_test_images/3.jpg')\n",
    "    frame, crop = extract_hand(img3, Hlower, Slower, Vlower, Hupper, Supper, Vupper, dil1_iter, erode1_iter, erode2_iter, dil2_iter, dil3_iter, dil4_iter)\n",
    "    cv2.imshow('original image 3', frame)\n",
    "#     cv2.imshow('crop 3',crop)\n",
    "    \n",
    "    img4 = cv2.imread('/Users/idofarhi/Documents/ITC/Projects/ASL/crop_test_images/4.jpg')\n",
    "    frame, crop = extract_hand(img4, Hlower, Slower, Vlower, Hupper, Supper, \n",
    "                               Vupper, dil1_iter, erode1_iter, erode2_iter, dil2_iter, dil3_iter, dil4_iter, False)\n",
    "    cv2.imshow('original image 4', frame)\n",
    "#     cv2.imshow('crop 4',crop)\n",
    "    \n",
    "    img5 = cv2.imread('/Users/idofarhi/Documents/ITC/Projects/ASL/crop_test_images/5.jpg')\n",
    "    frame, crop = extract_hand(img5, Hlower, Slower, Vlower, Hupper, Supper, \n",
    "                               Vupper, dil1_iter, erode1_iter, erode2_iter, dil2_iter, dil3_iter, dil4_iter, False)\n",
    "    cv2.imshow('original image 5', frame)\n",
    "#     cv2.imshow('crop 5',crop)\n",
    "    \n",
    "    img6 = cv2.imread('/Users/idofarhi/Documents/ITC/Projects/ASL/crop_test_images/6.jpg')\n",
    "    frame, crop = extract_hand(img6, Hlower, Slower, Vlower, Hupper, Supper, Vupper, dil1_iter, erode1_iter, erode2_iter, dil2_iter, dil3_iter, dil4_iter, False)\n",
    "    cv2.imshow('original image 6', frame)\n",
    "#     cv2.imshow('crop 6',crop)\n",
    "    \n",
    "#     img7 = cv2.imread('/Users/idofarhi/Documents/ITC/Projects/ASL/crop_test_images/7.jpg')\n",
    "#     frame, crop = extract_hand(img7, Hlower, Slower, Vlower, Hupper, Supper, Vupper, dil1_iter, erode1_iter, erode2_iter, dil2_iter, dil3_iter, dil4_iter)\n",
    "#     cv2.imshow('original image 7', frame)\n",
    "#     cv2.imshow('crop 7',crop)\n",
    "    \n",
    "    img8 = cv2.imread('/Users/idofarhi/Documents/ITC/Projects/ASL/crop_test_images/8.jpg')\n",
    "    frame, crop = extract_hand(img8, Hlower, Slower, Vlower, Hupper, Supper, Vupper, dil1_iter, erode1_iter, erode2_iter, dil2_iter, dil3_iter, dil4_iter)\n",
    "    cv2.imshow('original image 8', frame)\n",
    "#     cv2.imshow('crop 8',crop)\n",
    "    \n",
    "    # Press q to quit, p to print the current HSV values\n",
    "    if cv2.waitKey(100) & 0xFF == ord('p'):\n",
    "        print(Hlower,Slower,Vlower, Hupper,Supper,Vupper, dil3_iter, dil4_iter)\n",
    "\n",
    "    #close the output video by pressing 'q'\n",
    "    if cv2.waitKey(100) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.destroyAllWindows()\n",
    "# cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
