{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook focuses on extracting a concatenated vector of unique features for each image in place of using raw pixel values. It is assumed the hand is the foreground of the picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "from tensorflow.python.keras import Input, Model \n",
    "from tensorflow.python.keras.layers import Dense, Dropout\n",
    "import pixiedust\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "# img = cv2.imread('images/alef/1.jpg')\n",
    "\n",
    "# ft = cv2.freetype.createFreeType2()\n",
    "# ft.loadFontData(fontFileName='NewPeninimMT.ttc', id = 0)\n",
    "# ft.putText(img, 'הקידב', org=(15, 70), fontHeight=60, color=(255,255,255), \n",
    "#            thickness=-1, line_type=cv2.LINE_AA, bottomLeftOrigin=True)\n",
    "\n",
    "# cv2.imshow('א - Alef', img)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# cv2.destroyAllWindows()\n",
    "# cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "LETTERS = ['images/alef/', 'images/bet/', 'images/gimel/', 'images/daled/', 'images/hey/', 'images/vav/', \n",
    "           'images/zayin/', 'images/het/', 'images/tet/', 'images/yud/', 'images/haf/', 'images/lamed/', \n",
    "           'images/mem/', 'images/nun/', 'images/samech/', 'images/ayin/', 'images/pey/', 'images/tzadik/', \n",
    "           'images/kuf/', 'images/reish/', 'images/shin/', 'images/taf/', 'images/space/', 'images/empty/']\n",
    "\n",
    "def load_pictures(num_pictures = -1, test_sets = 1):\n",
    "    train_pictures, test_pictures = [], []\n",
    "    train_labels, test_labels = [], []\n",
    "    for k, letter in enumerate(tqdm(LETTERS)):\n",
    "#         print('loading pictures for:', letter[7:-1])\n",
    "        if num_pictures == -1:  # Use all pictures in the folder\n",
    "            path, dirs, files = next(os.walk(letter))\n",
    "            file_count = len(files)\n",
    "        else:\n",
    "            file_count = num_pictures\n",
    "        # Collect test pictures\n",
    "        for i in range(1, test_sets * 200 + 1): # Iterate in batches of 200\n",
    "            test_labels.append(k)\n",
    "            test_pictures.append(cv2.imread(letter + str(i) + '.jpg'))\n",
    "        # Collect train pictures\n",
    "        for i in range(test_sets * 200 + 1, file_count+1): # iterate starting where we stopped with test set\n",
    "            train_labels.append(k)\n",
    "            train_pictures.append(cv2.imread(letter + str(i) + '.jpg'))\n",
    "\n",
    "    return np.array(train_pictures), np.array(train_labels), np.array(test_pictures), np.array(test_labels)\n",
    "\n",
    "def get_hog() :\n",
    "    # (WinSize - BlockSize) % BlockStride must equal 0\n",
    "    # BlockSize % CellSize must equal 0\n",
    "    winSize = (200,200)\n",
    "    blockSize = (40,40)\n",
    "    blockStride = (40,40)\n",
    "    cellSize = (20,20)\n",
    "    nbins = 9\n",
    "    derivAperture = 1\n",
    "    winSigma = -1.\n",
    "    histogramNormType = 0\n",
    "    L2HysThreshold = 0.2\n",
    "    gammaCorrection = 1\n",
    "    nlevels = 64\n",
    "    signedGradients = True\n",
    "    hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins,derivAperture,winSigma,\\\n",
    "                            histogramNormType,L2HysThreshold,gammaCorrection,nlevels, signedGradients)\n",
    "    return hog\n",
    "\n",
    "def calculate_hog(hog, pictures):\n",
    "    # uses the labels only to print progress\n",
    "    hog_descriptors = []\n",
    "    pics_per_class = len(labels) / 24\n",
    "    for i, picture in enumerate(tqdm(pictures)):\n",
    "        hog_descriptors.append(np.squeeze(hog.compute(picture)))\n",
    "    return np.array(hog_descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading letter pictures ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1f4ecb2bd6f44d1b4f6d421747eac57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=24), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished loading pictures\n",
      "Loaded 48000 train pictures and 4800 test pictures\n",
      "CPU times: user 46.2 s, sys: 26.3 s, total: 1min 12s\n",
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('Loading letter pictures ... ')\n",
    "# Load data.\n",
    "train_pictures, train_labels, test_pictures, test_labels = load_pictures()\n",
    "print('Finished loading pictures')\n",
    "print('Loaded', len(train_pictures), 'train pictures and', len(test_pictures), 'test pictures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up HoG parameters\n",
      "Calculating HoG descriptor for train set\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "952931c600c7459f94ac822ac13aa305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=48000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating HoG descriptor for test set\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b22faf387a9e44ee8d97a28640eb57b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4800), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished calculating HoG descriptors.\n",
      "CPU times: user 43.4 s, sys: 8.02 s, total: 51.4 s\n",
      "Wall time: 54.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('Setting up HoG parameters')\n",
    "hog = get_hog()\n",
    "print('Calculating HoG descriptor for train set')\n",
    "hog_train = calculate_hog(hog, train_pictures)\n",
    "print('Calculating HoG descriptor for test set')\n",
    "hog_test = calculate_hog(hog, test_pictures)\n",
    "print('Finished calculating HoG descriptors.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data\n",
      "X_train shape: (43200, 900)\n",
      "y_train shape: (43200,)\n",
      "X_test shape: (4800, 900)\n",
      "y_test shape: (4800,)\n"
     ]
    }
   ],
   "source": [
    "print('Splitting data')\n",
    "X_train, X_val, y_train, y_val = train_test_split(hog_train, train_labels, test_size=0.1, random_state=42)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('X_test shape:', X_val.shape)\n",
    "print('y_test shape:', y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# NEED TO DO THIS BEFORE CONVERTING Y TO CATEGORICAL OTHERWISE IT WILL NOT RUN\n",
    "\n",
    "######     Training SVM Model     ##################\n",
    "\n",
    "svm = cv2.ml.SVM_create()\n",
    "# trainingDataMat = np.array(hog_descriptors, np.float32)\n",
    "# labelsMat = np.array([y_train], np.int32)\n",
    "svm.setType(cv2.ml.SVM_C_SVC)\n",
    "svm.setKernel(cv2.ml.SVM_RBF) # For long feature vector use SVM_LINEAR\n",
    "svm.setC(12.5)\n",
    "svm.setGamma(0.50625)\n",
    "svm.train(X_train, cv2.ml.ROW_SAMPLE, y_train)\n",
    "svm.save('HSL_svm.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of validation samples got wrong: 23\n",
      "Number of validation samples got right: 4777\n",
      "Validation accuracy:  99.52%\n",
      "Number of testing samples got wrong: 3265\n",
      "Number of testing samples got right: 1535\n",
      "Testing accuracy:  31.98%\n"
     ]
    }
   ],
   "source": [
    "######      Testing      ########################\n",
    "\n",
    "val_result = svm.predict(X_val)\n",
    "test_result = svm.predict(hog_test)\n",
    "\n",
    "#######   Check Accuracy   ########################\n",
    "\n",
    "mask_val = [0 if x == y_t else 1 for x, y_t in zip(val_result[1], y_val)]\n",
    "mask_test = [0 if x == y_t else 1 for x, y_t in zip(test_result[1], test_labels)]\n",
    "incorrect_val = np.count_nonzero(mask_val)\n",
    "incorrect_test = np.count_nonzero(mask_test)\n",
    "print('Number of validation samples got wrong:',incorrect_val)\n",
    "print('Number of validation samples got right:',len(y_val) - incorrect_val)\n",
    "print('Validation accuracy: {:6.2f}%'.format((len(y_val)-incorrect_val)/len(y_val)*100))\n",
    "print('Number of testing samples got wrong:',incorrect_test)\n",
    "print('Number of testing samples got right:',len(test_labels) - incorrect_test)\n",
    "print('Testing accuracy: {:6.2f}%'.format((len(test_labels)-incorrect_test)/len(test_labels)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00       200\n",
      "          1       0.25      0.20      0.22       200\n",
      "          2       0.45      0.76      0.57       200\n",
      "          3       0.53      0.39      0.45       200\n",
      "          4       0.25      0.41      0.31       200\n",
      "          5       0.47      0.94      0.63       200\n",
      "          6       0.76      0.33      0.46       200\n",
      "          7       0.01      0.01      0.01       200\n",
      "          8       0.37      0.73      0.49       200\n",
      "          9       0.06      0.11      0.08       200\n",
      "         10       0.76      0.61      0.68       200\n",
      "         11       0.88      0.43      0.58       200\n",
      "         12       0.18      0.05      0.08       200\n",
      "         13       0.08      0.01      0.01       200\n",
      "         14       0.73      0.14      0.23       200\n",
      "         15       0.27      0.01      0.03       200\n",
      "         16       0.00      0.00      0.00       200\n",
      "         17       0.89      0.32      0.46       200\n",
      "         18       0.47      0.58      0.52       200\n",
      "         19       0.00      0.00      0.00       200\n",
      "         20       0.95      0.31      0.47       200\n",
      "         21       0.15      0.71      0.24       200\n",
      "         22       0.38      0.20      0.26       200\n",
      "         23       0.28      0.43      0.34       200\n",
      "\n",
      "avg / total       0.38      0.32      0.30      4800\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# print(test_result[1])\n",
    "\n",
    "print(classification_report(test_labels, test_result[1]))\n",
    "# print(confusion_matrix(test_labels, test_result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# resp = model.predict(samples)\n",
    "# err = (labels != resp).mean()\n",
    "# print('Accuracy: %.2f %%' % ((1 - err)*100))\n",
    "\n",
    "# confusion = np.zeros((10, 10), np.int32)\n",
    "# for i, j in zip(labels, resp):\n",
    "#     confusion[int(i), int(j)] += 1\n",
    "# print('confusion matrix:')\n",
    "# print(confusion)\n",
    "\n",
    "# vis = []\n",
    "# for img, flag in zip(digits, resp == labels):\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "#     if not flag:\n",
    "#         img[...,:2] = 0\n",
    "\n",
    "#     vis.append(img)\n",
    "# return mosaic(25, vis)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_generic(x_train, depth):\n",
    "    inputs = Input(shape=(x_train[0].shape[0],))\n",
    "    f = Dense(1024, activation='relu')(inputs)\n",
    "    f = Dropout(rate = 0.5)(f)\n",
    "    for i in range(depth):\n",
    "        f = Dense(512, activation='relu')(f)\n",
    "        f = Dropout(rate = 0.5)(f)\n",
    "    f = Dense(256, activation='relu')(f)\n",
    "    f = Dropout(rate = 0.5)(f)\n",
    "    f = Dense(64, activation='relu')(f)\n",
    "    f = Dropout(rate = 0.4)(f)\n",
    "    outputs = Dense(24, activation='softmax')(f)\n",
    "    return Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Model for high dimensional input \n",
    "\n",
    "# def get_model_generic(x_train, depth):\n",
    "#     inputs = Input(shape=(x_train[0].shape[0],))\n",
    "#     f = Dense(2024, activation='relu')(inputs)\n",
    "#     f = Dropout(rate = 0.5)(f)\n",
    "#     for i in range(depth):\n",
    "#         f = Dense(1024, activation='relu')(f)\n",
    "#         f = Dropout(rate = 0.5)(f)\n",
    "#     f = Dense(256, activation='relu')(f)\n",
    "#     f = Dropout(rate = 0.5)(f)\n",
    "#     f = Dense(64, activation='relu')(f)\n",
    "#     f = Dropout(rate = 0.4)(f)\n",
    "#     outputs = Dense(24, activation='softmax')(f)\n",
    "#     return Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat = to_categorical(y_train, 24)\n",
    "y_val_cat = to_categorical(y_val, 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 3600)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2024)              7288424   \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 2024)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1024)              2073600   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 24)                1560      \n",
      "=================================================================\n",
      "Total params: 9,642,432\n",
      "Trainable params: 9,642,432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 43200 samples, validate on 4800 samples\n",
      "Epoch 1/70\n",
      "43200/43200 [==============================] - 21s 479us/step - loss: 3.2012 - acc: 0.0453 - val_loss: 3.1652 - val_acc: 0.0494\n",
      "Epoch 2/70\n",
      "43200/43200 [==============================] - 20s 474us/step - loss: 3.1007 - acc: 0.0694 - val_loss: 2.8167 - val_acc: 0.0965\n",
      "Epoch 3/70\n",
      "43200/43200 [==============================] - 19s 447us/step - loss: 2.7766 - acc: 0.1239 - val_loss: 2.2945 - val_acc: 0.3225\n",
      "Epoch 4/70\n",
      "43200/43200 [==============================] - 19s 450us/step - loss: 2.2268 - acc: 0.2790 - val_loss: 1.5950 - val_acc: 0.5279\n",
      "Epoch 5/70\n",
      "43200/43200 [==============================] - 20s 454us/step - loss: 1.6788 - acc: 0.4470 - val_loss: 1.0820 - val_acc: 0.6385\n",
      "Epoch 6/70\n",
      "43200/43200 [==============================] - 20s 454us/step - loss: 1.3128 - acc: 0.5617 - val_loss: 0.7725 - val_acc: 0.7440\n",
      "Epoch 7/70\n",
      "43200/43200 [==============================] - 20s 452us/step - loss: 1.1036 - acc: 0.6273 - val_loss: 0.7016 - val_acc: 0.7617\n",
      "Epoch 8/70\n",
      "43200/43200 [==============================] - 20s 452us/step - loss: 0.9704 - acc: 0.6752 - val_loss: 0.5076 - val_acc: 0.8294\n",
      "Epoch 9/70\n",
      "43200/43200 [==============================] - 20s 453us/step - loss: 0.8487 - acc: 0.7146 - val_loss: 0.4451 - val_acc: 0.8442\n",
      "Epoch 10/70\n",
      "43200/43200 [==============================] - 19s 451us/step - loss: 0.7997 - acc: 0.7300 - val_loss: 0.4021 - val_acc: 0.8650\n",
      "Epoch 11/70\n",
      "43200/43200 [==============================] - 19s 450us/step - loss: 0.7411 - acc: 0.7486 - val_loss: 0.3905 - val_acc: 0.8535\n",
      "Epoch 12/70\n",
      "43200/43200 [==============================] - 19s 449us/step - loss: 0.7102 - acc: 0.7603 - val_loss: 0.3563 - val_acc: 0.8729\n",
      "Epoch 13/70\n",
      "43200/43200 [==============================] - 19s 448us/step - loss: 0.6549 - acc: 0.7782 - val_loss: 0.3375 - val_acc: 0.8719\n",
      "Epoch 14/70\n",
      "43200/43200 [==============================] - 20s 457us/step - loss: 0.6690 - acc: 0.7766 - val_loss: 0.3318 - val_acc: 0.8804\n",
      "Epoch 15/70\n",
      "43200/43200 [==============================] - 20s 458us/step - loss: 0.6602 - acc: 0.7796 - val_loss: 0.3060 - val_acc: 0.8885\n",
      "Epoch 16/70\n",
      "43200/43200 [==============================] - 20s 465us/step - loss: 0.6373 - acc: 0.7868 - val_loss: 0.3040 - val_acc: 0.8942\n",
      "Epoch 17/70\n",
      "43200/43200 [==============================] - 20s 454us/step - loss: 0.6189 - acc: 0.7930 - val_loss: 0.2763 - val_acc: 0.9019\n",
      "Epoch 18/70\n",
      "43200/43200 [==============================] - 19s 445us/step - loss: 0.5770 - acc: 0.8062 - val_loss: 0.2775 - val_acc: 0.9108\n",
      "Epoch 19/70\n",
      "43200/43200 [==============================] - 20s 452us/step - loss: 0.5676 - acc: 0.8089 - val_loss: 0.2554 - val_acc: 0.9158\n",
      "Epoch 20/70\n",
      "43200/43200 [==============================] - 20s 453us/step - loss: 0.5269 - acc: 0.8247 - val_loss: 0.2318 - val_acc: 0.9246\n",
      "Epoch 21/70\n",
      "43200/43200 [==============================] - 20s 452us/step - loss: 0.5117 - acc: 0.8297 - val_loss: 0.2236 - val_acc: 0.9146\n",
      "Epoch 22/70\n",
      "43200/43200 [==============================] - 20s 461us/step - loss: 0.5207 - acc: 0.8294 - val_loss: 0.2282 - val_acc: 0.9279\n",
      "Epoch 23/70\n",
      "43200/43200 [==============================] - 20s 473us/step - loss: 0.4996 - acc: 0.8340 - val_loss: 0.2129 - val_acc: 0.9340\n",
      "Epoch 24/70\n",
      "43200/43200 [==============================] - 21s 484us/step - loss: 0.4794 - acc: 0.8401 - val_loss: 0.1940 - val_acc: 0.9387\n",
      "Epoch 25/70\n",
      "43200/43200 [==============================] - 20s 464us/step - loss: 0.4671 - acc: 0.8485 - val_loss: 0.1907 - val_acc: 0.9412\n",
      "Epoch 26/70\n",
      "43200/43200 [==============================] - 20s 460us/step - loss: 0.4461 - acc: 0.8518 - val_loss: 0.1999 - val_acc: 0.9371\n",
      "Epoch 27/70\n",
      "43200/43200 [==============================] - 20s 453us/step - loss: 0.4700 - acc: 0.8471 - val_loss: 0.1893 - val_acc: 0.9477\n",
      "Epoch 28/70\n",
      "43200/43200 [==============================] - 21s 481us/step - loss: 0.4572 - acc: 0.8527 - val_loss: 0.1754 - val_acc: 0.9433\n",
      "Epoch 29/70\n",
      "43200/43200 [==============================] - 20s 457us/step - loss: 0.4695 - acc: 0.8478 - val_loss: 0.2059 - val_acc: 0.9373\n",
      "Epoch 30/70\n",
      "43200/43200 [==============================] - 20s 458us/step - loss: 0.4705 - acc: 0.8503 - val_loss: 0.1852 - val_acc: 0.9390\n",
      "Epoch 31/70\n",
      "43200/43200 [==============================] - 20s 459us/step - loss: 0.4535 - acc: 0.8532 - val_loss: 0.1630 - val_acc: 0.9485\n",
      "Epoch 32/70\n",
      "43200/43200 [==============================] - 20s 457us/step - loss: 0.4312 - acc: 0.8612 - val_loss: 0.1680 - val_acc: 0.9473\n",
      "Epoch 33/70\n",
      "43200/43200 [==============================] - 20s 453us/step - loss: 0.4149 - acc: 0.8670 - val_loss: 0.1529 - val_acc: 0.9485\n",
      "Epoch 34/70\n",
      "43200/43200 [==============================] - 19s 449us/step - loss: 0.4128 - acc: 0.8675 - val_loss: 0.1546 - val_acc: 0.9431\n",
      "Epoch 35/70\n",
      "43200/43200 [==============================] - 20s 453us/step - loss: 0.4016 - acc: 0.8699 - val_loss: 0.1712 - val_acc: 0.9462\n",
      "Epoch 36/70\n",
      "43200/43200 [==============================] - 20s 452us/step - loss: 0.3974 - acc: 0.8731 - val_loss: 0.1490 - val_acc: 0.9550\n",
      "Epoch 37/70\n",
      "43200/43200 [==============================] - 19s 448us/step - loss: 0.3956 - acc: 0.8735 - val_loss: 0.1526 - val_acc: 0.9481\n",
      "Epoch 38/70\n",
      "43200/43200 [==============================] - 19s 449us/step - loss: 0.3965 - acc: 0.8739 - val_loss: 0.1388 - val_acc: 0.9571\n",
      "Epoch 39/70\n",
      "43200/43200 [==============================] - 20s 454us/step - loss: 0.3873 - acc: 0.8786 - val_loss: 0.1416 - val_acc: 0.9592\n",
      "Epoch 40/70\n",
      "43200/43200 [==============================] - 21s 489us/step - loss: 0.3874 - acc: 0.8778 - val_loss: 0.1427 - val_acc: 0.9583\n",
      "Epoch 41/70\n",
      "43200/43200 [==============================] - 20s 456us/step - loss: 0.4004 - acc: 0.8737 - val_loss: 0.1379 - val_acc: 0.9604\n",
      "Epoch 42/70\n",
      "43200/43200 [==============================] - 20s 453us/step - loss: 0.3965 - acc: 0.8746 - val_loss: 0.1478 - val_acc: 0.9506\n",
      "Epoch 43/70\n",
      "43200/43200 [==============================] - 19s 451us/step - loss: 0.3958 - acc: 0.8750 - val_loss: 0.1314 - val_acc: 0.9610\n",
      "Epoch 44/70\n",
      "43200/43200 [==============================] - 20s 453us/step - loss: 0.3789 - acc: 0.8797 - val_loss: 0.1264 - val_acc: 0.9606\n",
      "Epoch 45/70\n",
      "43200/43200 [==============================] - 20s 455us/step - loss: 0.3747 - acc: 0.8844 - val_loss: 0.1229 - val_acc: 0.9606\n",
      "Epoch 46/70\n",
      "43200/43200 [==============================] - 20s 453us/step - loss: 0.3337 - acc: 0.8960 - val_loss: 0.1148 - val_acc: 0.9621\n",
      "Epoch 47/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43200/43200 [==============================] - 19s 450us/step - loss: 0.3379 - acc: 0.8950 - val_loss: 0.1170 - val_acc: 0.9596\n",
      "Epoch 48/70\n",
      "43200/43200 [==============================] - 19s 450us/step - loss: 0.3292 - acc: 0.8971 - val_loss: 0.1195 - val_acc: 0.9625\n",
      "Epoch 49/70\n",
      "43200/43200 [==============================] - 20s 453us/step - loss: 0.3328 - acc: 0.8967 - val_loss: 0.1185 - val_acc: 0.9652\n",
      "Epoch 50/70\n",
      "43200/43200 [==============================] - 20s 452us/step - loss: 0.3241 - acc: 0.9002 - val_loss: 0.1091 - val_acc: 0.9681\n",
      "Epoch 51/70\n",
      "43200/43200 [==============================] - 19s 446us/step - loss: 0.3083 - acc: 0.9041 - val_loss: 0.1246 - val_acc: 0.9623\n",
      "Epoch 52/70\n",
      "43200/43200 [==============================] - 19s 446us/step - loss: 0.3230 - acc: 0.9012 - val_loss: 0.0947 - val_acc: 0.9706\n",
      "Epoch 53/70\n",
      "43200/43200 [==============================] - 20s 452us/step - loss: 0.3170 - acc: 0.9022 - val_loss: 0.1050 - val_acc: 0.9704\n",
      "Epoch 54/70\n",
      "43200/43200 [==============================] - 20s 466us/step - loss: 0.3097 - acc: 0.9053 - val_loss: 0.1225 - val_acc: 0.9610\n",
      "Epoch 55/70\n",
      "43200/43200 [==============================] - 19s 449us/step - loss: 0.3238 - acc: 0.8995 - val_loss: 0.1094 - val_acc: 0.9669\n",
      "Epoch 56/70\n",
      "43200/43200 [==============================] - 20s 457us/step - loss: 0.3051 - acc: 0.9063 - val_loss: 0.1063 - val_acc: 0.9673\n",
      "Epoch 57/70\n",
      "43200/43200 [==============================] - 20s 457us/step - loss: 0.2935 - acc: 0.9101 - val_loss: 0.0986 - val_acc: 0.9685\n",
      "Epoch 58/70\n",
      "43200/43200 [==============================] - 20s 455us/step - loss: 0.2941 - acc: 0.9118 - val_loss: 0.1019 - val_acc: 0.9662\n",
      "Epoch 59/70\n",
      "43200/43200 [==============================] - 20s 455us/step - loss: 0.2971 - acc: 0.9102 - val_loss: 0.0896 - val_acc: 0.9727\n",
      "Epoch 60/70\n",
      "43200/43200 [==============================] - 20s 452us/step - loss: 0.2880 - acc: 0.9135 - val_loss: 0.0997 - val_acc: 0.9683\n",
      "Epoch 61/70\n",
      "43200/43200 [==============================] - 20s 453us/step - loss: 0.2808 - acc: 0.9148 - val_loss: 0.0895 - val_acc: 0.9731\n",
      "Epoch 62/70\n",
      "43200/43200 [==============================] - 20s 455us/step - loss: 0.2778 - acc: 0.9158 - val_loss: 0.0970 - val_acc: 0.9700\n",
      "Epoch 63/70\n",
      "43200/43200 [==============================] - 20s 457us/step - loss: 0.2887 - acc: 0.9117 - val_loss: 0.0924 - val_acc: 0.9696\n",
      "Epoch 64/70\n",
      "43200/43200 [==============================] - 20s 454us/step - loss: 0.2741 - acc: 0.9155 - val_loss: 0.0952 - val_acc: 0.9717\n",
      "Epoch 65/70\n",
      "43200/43200 [==============================] - 19s 449us/step - loss: 0.2786 - acc: 0.9155 - val_loss: 0.0951 - val_acc: 0.9698\n",
      "Epoch 66/70\n",
      "43200/43200 [==============================] - 20s 458us/step - loss: 0.2852 - acc: 0.9134 - val_loss: 0.0846 - val_acc: 0.9740\n",
      "Epoch 67/70\n",
      "43200/43200 [==============================] - 20s 458us/step - loss: 0.2789 - acc: 0.9156 - val_loss: 0.0835 - val_acc: 0.9754\n",
      "Epoch 68/70\n",
      "43200/43200 [==============================] - 20s 459us/step - loss: 0.2838 - acc: 0.9153 - val_loss: 0.0845 - val_acc: 0.9733\n",
      "Epoch 69/70\n",
      "43200/43200 [==============================] - 20s 453us/step - loss: 0.2651 - acc: 0.9203 - val_loss: 0.0792 - val_acc: 0.9765\n",
      "Epoch 70/70\n",
      "43200/43200 [==============================] - 19s 451us/step - loss: 0.2875 - acc: 0.9118 - val_loss: 0.1047 - val_acc: 0.9677\n"
     ]
    }
   ],
   "source": [
    "model = get_model_generic(X_train, 1)                    \n",
    "print(model.summary())\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(x=X_train, y=y_train_cat, batch_size=1024, epochs=70, validation_data=(X_val, y_val_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800/4800 [==============================] - 2s 393us/step\n",
      "Test score: 5.551863814030342\n",
      "Test accuracy: 0.20145833333333332\n"
     ]
    }
   ],
   "source": [
    "y_test_cat = to_categorical(test_labels, 24)\n",
    "score, acc = model.evaluate(hog_test, y_test_cat)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5200\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {0: 1.,\n",
    "                1: 50.,\n",
    "                2: 2.}\n",
    "model.fit(X_train, Y_train, nb_epoch=5, batch_size=32, class_weight=class_weight)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "322px",
    "left": "1157.27px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
