{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from datetime import datetime\n",
    "from itertools import cycle\n",
    "from PIL import Image\n",
    "from time import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/ds3/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras import Input, Model\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.python.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILENAME = r'C:/Users/leohe/Documents/ITC/HIVE/Challenge/sign_language/HSL_images.zip'\n",
    "FILENAME = r'/data/sign_language/HSL_images.zip'\n",
    "\n",
    "\n",
    "# LABEL = {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9,\n",
    "#          'K':10, 'L':11, 'M':12, 'N':13, 'O':14, 'P':15, 'Q':16, 'R':17, 'S':18, 'T':19,\n",
    "#          'U':20, 'V':21, 'W':22, 'X':23, 'Y':24, 'Z':25, \n",
    "#          'del':26, 'nothing':27, 'space':28}\n",
    "\n",
    "LABEL = {'alef': 0, 'bet': 1, 'gimel': 2, 'daled': 3, \n",
    "         'hey': 4, 'vav': 5, 'zayin': 6, 'het': 7, 'tet': 8, \n",
    "         'yud': 9, 'haf': 10, 'lamed': 11, 'mem': 12, 'nun': 13, \n",
    "         'samech': 14, 'ayin': 15, 'pey': 16, 'tzadik': 17, \n",
    "         'kuf': 18, 'reish': 19, 'shin': 20, 'taf': 21, \n",
    "         'space': 22, 'empty': 23}\n",
    "\n",
    "\n",
    "NUM_REGEX = r\"[0-9]+\"\n",
    "\n",
    "# SAMPLE_SIZE = 30\n",
    "N_TRAIN = 200 * 24 * 10\n",
    "N_TEST  = 200 * 24 * 1 #87000 // SAMPLE_SIZE# total number of images in the training set\n",
    "IMG_SIZE = 200 # original image size, to be resized\n",
    "CHANNEL = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idos_filter(img, *options):\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- loading the images into a np.array from inside the zip file\n",
    "- loading and translating the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15660fbe6eed4186b933c2cfacfa655c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=52825), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_count = 0\n",
    "x_train  = np.zeros((N_TRAIN, IMG_SIZE, IMG_SIZE, CHANNEL), dtype='float16')\n",
    "y_train = np.zeros((N_TRAIN, 1), dtype='uint8')\n",
    "\n",
    "test_count = 0\n",
    "x_test  = np.zeros((N_TEST, IMG_SIZE, IMG_SIZE, CHANNEL), dtype='float16')\n",
    "y_test = np.zeros((N_TEST, 1), dtype='uint8')\n",
    "\n",
    "with ZipFile(FILENAME) as archive:\n",
    "    for entry in tqdm(archive.infolist()):\n",
    "        name = str(entry).split(\"'\")[1].replace('/', ' ').split()\n",
    "        if len(name) == 3:\n",
    "            if int(re.findall(NUM_REGEX, name[2])[0]) <= 200:\n",
    "                with archive.open(entry) as file:\n",
    "                    img = np.array(Image.open(file))\n",
    "                x_test[test_count] = idos_filter(img) / 255\n",
    "                y_test[test_count] = LABEL[name[1]]\n",
    "                test_count += 1\n",
    "            elif 200 < int(re.findall(NUM_REGEX, name[2])[0]):\n",
    "                with archive.open(entry) as file:\n",
    "                    img = np.array(Image.open(file))\n",
    "                x_train[train_count] = idos_filter(img) / 255\n",
    "                y_train[train_count] = LABEL[name[1]]\n",
    "                train_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200, 200, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 198, 198, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 196, 196, 64)      36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 196, 196, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 98, 98, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 96, 96, 16)        9232      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 94, 94, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 94, 94, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 47, 47, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 45, 45, 4)         580       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 43, 43, 4)         148       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 43, 43, 4)         16        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 21, 21, 4)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1764)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 400)               706000    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               80200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 24)                1224      \n",
      "=================================================================\n",
      "Total params: 874,010\n",
      "Trainable params: 873,842\n",
      "Non-trainable params: 168\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=x_train.shape[1:])\n",
    "f = layers.Conv2D(64, (3, 3), kernel_initializer='glorot_normal')(inputs)\n",
    "f = layers.Conv2D(64, (3, 3), kernel_initializer='glorot_normal', activation='relu')(f)\n",
    "f = layers.BatchNormalization()(f)\n",
    "f = layers.MaxPool2D()(f)\n",
    "f = layers.Conv2D(16, (3, 3), kernel_initializer='glorot_normal', activation='relu')(f)\n",
    "f = layers.Conv2D(16, (3, 3), kernel_initializer='glorot_normal', activation='relu')(f)\n",
    "f = layers.BatchNormalization()(f)\n",
    "f = layers.MaxPool2D()(f)\n",
    "f = layers.Conv2D( 4, (3, 3), kernel_initializer='glorot_normal', activation='relu')(f)\n",
    "f = layers.Conv2D( 4, (3, 3), kernel_initializer='glorot_normal', activation='relu')(f)\n",
    "f = layers.BatchNormalization()(f)\n",
    "f = layers.MaxPool2D()(f)\n",
    "f = layers.Flatten()(f)\n",
    "f = layers.Dense(400, activation='relu', kernel_initializer='glorot_normal')(f)\n",
    "f = layers.Dropout(0.2)(f)\n",
    "f = layers.Dense(200, activation='relu', kernel_initializer='glorot_normal')(f)\n",
    "f = layers.Dropout(0.2)(f)\n",
    "f = layers.Dense(100, activation='relu', kernel_initializer='glorot_normal')(f)\n",
    "f = layers.Dropout(0.2)(f)\n",
    "f = layers.Dense(100, activation='relu', kernel_initializer='glorot_normal')(f)\n",
    "f = layers.Dropout(0.2)(f)\n",
    "f = layers.Dense( 50, activation='relu', kernel_initializer='glorot_normal')(f)\n",
    "f = layers.Dropout(0.2)(f)\n",
    "outputs = layers.Dense(len(np.unique(y_train)), activation='softmax')(f)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "print(model.summary())\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "48000/48000 [==============================] - 627s 13ms/step - loss: 1.9572 - acc: 0.3955\n",
      "Epoch 2/2\n",
      "48000/48000 [==============================] - 488s 10ms/step - loss: 0.4958 - acc: 0.8379\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x= x_train, \n",
    "                    y= to_categorical(y_train, len(np.unique(y_train))), \n",
    "                    batch_size= 128, \n",
    "                    epochs= 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800/4800 [==============================] - 16s 3ms/step\n",
      "2.5002824674298365 0.5108333333333334\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x=x_test, y=to_categorical(y_test, len(np.unique(y_test))))\n",
    "print(loss, acc)\n",
    "probabilities = model.predict(x=x_test)\n",
    "y_pred = np.argmax(probabilities, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.27      0.35      0.31       200\n",
      "          1       0.64      0.56      0.60       200\n",
      "          2       0.37      0.46      0.41       200\n",
      "          3       0.79      0.59      0.68       200\n",
      "          4       0.48      0.67      0.56       200\n",
      "          5       0.45      0.63      0.52       200\n",
      "          6       0.77      0.70      0.73       200\n",
      "          7       0.28      0.43      0.34       200\n",
      "          8       0.61      0.62      0.62       200\n",
      "          9       0.26      0.47      0.34       200\n",
      "         10       0.55      0.53      0.54       200\n",
      "         11       0.79      0.72      0.76       200\n",
      "         12       0.65      0.14      0.23       200\n",
      "         13       0.55      0.06      0.10       200\n",
      "         14       0.13      0.09      0.10       200\n",
      "         15       0.59      0.79      0.68       200\n",
      "         16       0.44      0.43      0.44       200\n",
      "         17       0.81      0.90      0.85       200\n",
      "         18       0.67      0.88      0.76       200\n",
      "         19       0.48      0.33      0.39       200\n",
      "         20       0.43      0.88      0.57       200\n",
      "         21       0.25      0.06      0.10       200\n",
      "         22       0.72      0.41      0.52       200\n",
      "         23       0.84      0.59      0.70       200\n",
      "\n",
      "avg / total       0.53      0.51      0.49      4800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
